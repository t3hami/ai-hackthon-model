{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#VGG Face\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.ZeroPadding2D((1,1)))\n",
    "model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(layers.Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Convolution2D(2622, (1, 1)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'images/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=5,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'pics_data/validation',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      " 8/10 [=======================>......] - ETA: 39s - loss: 2.2008 - acc: 0.1250 "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image \n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=10,\n",
    "#     validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('students_faces.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"cats_and_dogs_small_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('images/train/tehami/tehami1.jpg', target_size=(224,224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "result = model.predict(test_image)\n",
    "np.argmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest')\n",
    "from keras.preprocessing import image\n",
    "\n",
    "fnames = [os.path.join(train_cats_dir, fname) for\n",
    "    fname in os.listdir(train_cats_dir)]\n",
    "img_path = fnames[3]\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
